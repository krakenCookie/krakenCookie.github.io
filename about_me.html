---
layout: page
title: About Me
author: Zach
permalink: /about/
---
<header>

    {% if site.compass.logo %}
    <div class="logo-container">
      <a class="round-pic" style="background-image: url('{{ site.baseurl }}{{ site.facepic }}')"></a>
    </div>
    {% endif %}

</header>
<main>
    <h1> Why is your logo a weird-looking fruit-thing? </h1>
    <p> It's a <a href="https://en.wikipedia.org/wiki/Asimina_triloba">pawpaw</a>, 
        the largest edible fruit indigenous to North America. (Gourds are <em>vegetables</em>, people!) 
        It's native to where I grew up (Indiana), and a well-kept delicious secret even to locals. Imagine a cross 
        between banana custard and a mango--pawpaws are absolutely amazing!</p>
    <p> As a fellow Hoosier <em>also</em> aspiring to greatness, I have a strong affinity for the little tree, and on top of
        that, I'm a big pawpaw proselytizer--I've gotten my labmates hooked on the stuff! </p>

    <h1 id="research"> What research are you doing at the moment? </h1>
    <p> My interests are still as broad as ever, but I've been focusing on how people understand each other when 
        they sometimes talk so differently. This has manifested itself in a bunch of different projects. </p>
    <ul>
        <li><h3 style="display: inline">How does the need for clear communication shape our language?
            <br />(Computational modeling)</h3> &nbsp; Languages all change over time,
            as do the sounds that are used in those languages. Sometimes, two distinct sounds <b>merge</b> to form a single sound. For example,
            many parts of America now pronounce <em>caught</em> and <em>cot</em> the same. You might think which sounds merge would be
            completely random, but if the need to understand each other exerts some pressure on how sounds change, some changes are more
            likely than others. Theoretically, the way we <em>use</em> our languages could actually play a hand in how they evolve!
            <br />
            I'm developing <b>computational models</b> to estimate the impact of phonological mergers on how easy it is to understand each word in
            the English language. Unlike previous work, I'm doing this in a way that attempts to capture how the <b>acoustic/perceptual similarities
            of different sounds</b> interact with the structure of the lexicon and how English is used (e.g., incorporating context). 
            <br /><br/></li>
        
        <li><h3 style="display: inline">How do we get better at understanding accents?
            <br />(Pupillometry)</h3> &nbsp; Unfamiliarly accented speech can be hard to process initially,
            but we can rapidly improve our understanding by merely listening for a few minutes. Is this adaptation merely surface-level
            changes in comprehension and reaction times, or does our processing become more efficient at a deeper level? <b>Pupil dilation</b>
            is linked to certain kinds of processing difficulty--I'm interested in using pupillometry to explore how accent adaptation
            affects processing. 
            <br/><br/></li>
        <li><h3 style="display: inline">How do we optimally handle information to learn an accent?
            <br />(Over-the-web behavioral experiments)</h3> &nbsp; There is a common conception in linguistics that we <em>immediately compress</em>
            linguistic information--that as soon as we categorize linguistic elements (sounds/words/meanings), we discard the information that led 
            us to that choice. For example, it's a common occurence to remember the gist of a sentence, but not remember the exact words or
            how those words sounded. But recent studies have found that information that comes <em>after</em> we've supposedly categorized
            linguistic elements can still influence them. This suggests that we actually <b>maintain some lower-level information</b> about these
            elements instead of discarding it as quickly as possible.
            <br/>I'm using my knowledge of accent adaptation to find out what sort of information listeners maintain and how long they can 
            maintain it, while also avoiding constraints in previous research. Conducting experiments over the web with <b>Amazon's Mechanical
            Turk</b>, I have demonstrated that <b>subtitles</b> improve adaptation to foreign accents. By adjusting the delay between speech and subtitles
            and observing the benefit, I have been able to investigate perceptual maintenance.
            </li>
    </ul>
    
    <h1> What else are you interested in non-academically?</h1>
    <p> I'm interested in pretty much everything, but right now I'm really pumped about applying the computational and statistical 
        skills I've developed to things I care about personally. It's fun way easier than most people think.  I really enjoy reading webcomics, 
        but I hate being in limbo about whether content creators are going to keep updating after their work, so I'm in the process of 
        making a Bayesian model that will be able to estimate how likely it will be before they update again. </p>
        

    
    
    <h1> How else I can connect with you?</h1>
    <div class="eqi-container" style="margin: 0 25%">
        <div><a href="https://github.com/burchill/"><span class="fa fa-github fa-3x main-list-item-icon"></span></a></div>
        <div><a href="https://www.linkedin.com/in/zachary-burchill/"><span class="fa fa-linkedin fa-3x main-list-item-icon"></span></a></div> 
        <div><a href="https://twitter.com/zachburchill/"><span class="fa fa-twitter fa-3x main-list-item-icon"></span></a></div>
    </div>
    <br/>
    
    
    <h1> Why did you think a Q&A format was a good idea for an 'About Me' page? </h1>
    <p> Ya got me. My landing page was already descriptive enough for most introductions--I really just made this page
        to explain what the pawpaw logo was. 
    <br/><br/></p>
    
</main>

