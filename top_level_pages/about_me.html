---
layout: page
title: About Me
author: Zach
permalink: /about/
---
<header>

    {% if site.compass.logo %}
    <div class="logo-container">
      <a class="round-pic" style="background-image: url('{{ site.baseurl }}{{ site.facepic }}')"></a>
    </div>
    {% endif %}

</header>
<main>
    <h1> Why is my logo a weird-looking fruit-thing? </h1>
    <p> It's a <a href="https://en.wikipedia.org/wiki/Asimina_triloba">pawpaw</a>, 
        the largest edible fruit indigenous to North America. (Gourds are <em>vegetables</em>, people!) 
        It's native to where I grew up (Indiana), and a delicious well-kept secret, even to locals. Imagine a cross 
        between banana custard and a mango&mdash;pawpaws are absolutely amazing!</p>
    <p> As a fellow Hoosier <em>also</em> aspiring to greatness, I have a strong affinity for the little tree, and on top of
        that, I'm a big pawpaw proselytizer&mdash;I've gotten my labmates hooked on the stuff! </p>

    <h1 id="research"> What research am I doing at the moment? </h1>
    <p> My interests are still as broad as ever, but I've been focusing on how people understand each other when 
        they sometimes talk so differently. This has manifested itself in a bunch of different projects. </p>
    <ul>
    	<li><h3 style="display: inline">How can researchers improve statistical power for skewed data? 
            <br />(Large-scale statistical modeling)</h3> &nbsp; Many statistical techniques, like ANOVAs and linear mixed models, make a certain assumption about their data: namely,
            that the part of the data they can't account for (i.e., the "residuals") are distributed in a bell-shaped, "normal" distribution. 
            But researchers still use these techniques with data where this is known to be false, such as with reading times. How much do violations
            of these assumptions actually <em>impact</em> our ability to get results using these methods? How can statisticians and researchers <b>improve their statistical power</b>?
            <br />
            My researcher here constitutes the <b>first ever</b> large-scale power simulation of reading times (RTs) using <b>natural bootstrapped RT data</b>. In essence,
            with the University of Rochester's computing cluster I've been running <b>millions upon millions of statistical models in parallel</b> on 
            actual RT data, comparing traditional statistical techniques with ones that power-transform the data. My research here should provide
            scientists with better knowledge on how to <b>detect effects in skewed data</b>!
            <br /><br/></li>
    	
        <li><h3 style="display: inline">How does the need for clear communication shape our language?
            <br />(Computational modeling)</h3> &nbsp; Languages all change over time,
            as do the sounds that are used in those languages. Sometimes, two distinct sounds <b>merge</b> to form a single sound. For example,
            many parts of America now pronounce <em>caught</em> and <em>cot</em> the same. You might think which sounds merge would be
            completely random, but if the need to understand each other exerts some pressure on how sounds change, some changes are more
            likely than others. Theoretically, the way we <em>use</em> our languages could actually play a hand in how they evolve!
            <br />
            I'm developing <b>computational models</b> to estimate the impact of phonological mergers on how easy it is to understand each word in
            the English language. Unlike previous work, I'm doing this in a way that attempts to capture how the <b>acoustic/perceptual similarities
            of different sounds</b> interact with the structure of the lexicon and how English is used (e.g., incorporating context). 
            <br /><br/></li>
        
        <li><h3 style="display: inline">How do we get better at understanding accents?
            <br />(Pupillometry)</h3> &nbsp; Unfamiliarly accented speech can be hard to process initially,
            but we can rapidly improve our understanding by merely listening for a few minutes. Is this adaptation merely surface-level
            changes in comprehension and reaction times, or does our processing become more efficient at a deeper level? <b>Pupil dilation</b>
            is linked to certain kinds of processing difficulty&mdash;I'm interested in using pupillometry to explore how accent adaptation
            affects processing. 
            <br/><br/></li>
            
        <li><h3 style="display: inline">How do we optimally handle information to learn an accent?
            <br />(Over-the-web behavioral experiments)</h3> &nbsp; There is a common conception in linguistics that we <em>immediately compress</em>
            linguistic information&mdash;that as soon as we categorize linguistic elements (sounds/words/meanings), we discard the information that led 
            us to that choice. For example, it's a common occurence to remember the gist of a sentence, but not remember the exact words or
            how those words sounded. But recent studies have found that information that comes <em>after</em> we've supposedly categorized
            linguistic elements can still influence them. This suggests that we actually <b>maintain some lower-level information</b> about these
            elements instead of discarding it as quickly as possible.
            <br/>I'm using my knowledge of accent adaptation to find out what sort of information listeners maintain and how long they can 
            maintain it, while also avoiding constraints in previous research. Conducting experiments over the web with <b>Amazon's Mechanical
            Turk</b>, I have demonstrated that <b>subtitles</b> improve adaptation to foreign accents. By adjusting the delay between speech and subtitles
            and observing the benefit, I have been able to investigate perceptual maintenance.
            </li>
    </ul>
    
    <h1 style="text-align:left;"> What else am I interested in non-academically?</h1>
    <p> I'm interested in pretty much everything, but right now I'm really pumped about applying the computational and statistical 
        skills I've developed to things I care about personally. It's fun and way easier than most people think.  I really enjoy reading webcomics, 
        but I hate being in limbo about whether content creators are going to keep updating after their work, so I'm in the process of 
        making a Bayesian model that will be able to estimate how likely it will be before they update again. In the meantime, I've also
        looked at political finance and other fun areas! </p>
        

    
    
    <h1> How else can you connect with me?</h1>
    <div class="eqi-container" style="margin: 0 25%">
        <div><a href="https://github.com/varunhc/"><span class="fa fa-github fa-3x main-list-item-icon"></span></a></div>
        <div><a href="https://www.linkedin.com/in/varunhc/"><span class="fa fa-linkedin fa-3x main-list-item-icon"></span></a></div>
    </div>
    <br/>
    
</main>

